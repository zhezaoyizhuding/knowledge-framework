[TOC]

## 1、什么是分布式锁

多个实例访问共享资源时加的锁。一般来说，分布式锁需要满足的特性有：

1. 互斥性：在任何时刻，对于同一条数据，只有一台应用可以获取到分布式锁；
2. 高可用性：在分布式场景下，一小部分服务器宕机不影响正常使用，这种情况就需要将提供分布式锁的服务以集群的方式部署；
3. 防止锁超时：如果客户端没有主动释放锁，服务器会在一段时间之后自动释放锁，防止客户端宕机或者网络不可达时产生死锁；

4. 独占性：加锁解锁必须由同一台服务器进行，也就是锁的持有者才可以释放锁，不能出现你加的锁，别人给你解锁了；

## 2、三种实现方式

### 1、数据库

#### 1.1 数据库主键

insert获取锁，delete释放锁

它同样存在一些问题：

- 没有失效时间，容易导致死锁；

- 依赖数据库的可用性，一旦数据库挂掉，锁就马上不可用；

- 这把锁只能是非阻塞的，因为数据的 insert 操作，一旦插入失败就会直接报错。没有获得锁的线程并不会进入排队队列，要想再次获得锁就要再次触发获得锁操作；

- 这把锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁。因为数据库中数据已经存在了。

#### 1.2 乐观锁

增加一个version字段，获取锁则对version 加 1。先查询后更新，每次更新会将查询的版本号用于比较，如果相等则在此期间没有线程对他进行修改，则获得锁；如果不相等，则获取锁失败。

删除记录释放锁

#### 1.3 悲观锁

利用数据库行锁机制。select ... for update。如果线程没阻塞，则获得锁。阻塞则等待获取锁。

### 2、redis锁

#### 2.1、setex 或者 setnx + Lua

```text
# 设置键值的同时，设置过期时间，单位秒，如果key已经存在，SETEX命令将覆写旧值。
SETEX key seconds value

# 设置键值的同时，设置过期时间，单位毫秒，如果key已经存在，PSETEX命令将覆写旧值。
PSETEX key milliseconds value
```

直接设置值附带过期时间，避免setnx命令与expire命令合用的原子性问题。或者使用Lua脚本解决原子性问题。

> 值是唯一键：全局锁；key是唯一键：可用于幂等

存在问题：

- **死锁**：设置过期时间
- **过期时间评估不好，锁提前过期**：守护线程，自动续期
- **锁被别人释放**：Lua脚本，先检查锁，再释放锁
- **主从同步问题**:  其他实现代替，比如redlock

#### 2.2、redlock

##### 2.2.1 实现

Redlock 的方案基于 2 个前提：

1. 不再需要部署**从库**和**哨兵**实例，只部署**主库**
2. 但主库要部署多个，官方推荐至少 5 个实例

也就是说，想使用 Redlock，你至少要部署 5 个 Redis 实例，而且都是主库，它们之间没有任何关系，都是一个个孤立的实例。

> **注意：不是部署 Redis Cluster，就是部署 5 个简单的 Redis 实例。**

![img](https://yusheng-picgo.oss-cn-beijing.aliyuncs.com/picgo/v2-fe3c3bcc9d9a3d68751ef66a939c5423_1440w.jpg)

Redlock 具体如何使用呢？

整体的流程是这样的，一共分为 5 步：

1. 客户端先获取「当前时间戳T1」
2. 客户端依次向这 5 个 Redis 实例发起加锁请求（SET 命令），且每个请求会设置超时时间（毫秒级，要远小于锁的有效时间），如果某一个实例加锁失败（包括网络超时、锁被其它人持有等各种异常情况），就立即向下一个 Redis 实例申请加锁
3. 如果客户端从 >=3 个（大多数）以上 Redis 实例加锁成功，则再次获取「当前时间戳T2」，如果 T2 - T1 < 锁的过期时间，此时，认为客户端加锁成功，否则认为加锁失败
4. 加锁成功，去操作共享资源
5. 加锁失败，向「全部节点」发起释放锁请求（Lua 脚本释放锁）

![img](https://yusheng-picgo.oss-cn-beijing.aliyuncs.com/picgo/v2-759e198c371f6f3471dfadd54c908c0e_1440w.jpg)

总结一下，有 4 个重点：

1. 客户端在多个 Redis 实例上申请加锁
2. 必须保证大多数节点加锁成功
3. 大多数节点加锁的总耗时，要小于锁设置的过期时间
4. 释放锁，要向全部节点发起释放锁请求

> **为什么要在多个实例上加锁？**

本质上是为了「容错」，部分实例异常宕机，剩余的实例加锁成功，整个锁服务依旧可用。

> **为什么大多数加锁成功，才算成功？**

多个 Redis 实例一起来用，其实就组成了一个「分布式系统」。

如果存在「故障」节点，只要大多数节点正常，那么整个系统依旧是可以提供正确服务的。

> **为什么步骤 3 加锁成功后，还要计算加锁的累计耗时？**

因为操作的是多个节点，所以耗时肯定会比操作单个实例耗时更久，而且，因为是网络请求，网络情况是复杂的，有可能存在**延迟、丢包、超时**等情况发生，网络请求越多，异常发生的概率就越大。

所以，即使大多数节点加锁成功，但如果加锁的累计耗时已经「超过」了锁的过期时间，那此时有些实例上的锁可能已经失效了，这个锁就没有意义了。

> **为什么释放锁，要操作所有节点？**

在某一个 Redis 节点加锁时，可能因为「网络原因」导致加锁失败。

例如，客户端在一个 Redis 实例上加锁成功，但在读取响应结果时，网络问题导致**读取失败**，那这把锁其实已经在 Redis 上加锁成功了。

所以，释放锁时，不管之前有没有加锁成功，需要释放「所有节点」的锁，以保证清理节点上「残留」的锁。

##### 2.2.2 Antirez 和 Martin 关于 Redlock 的争论

###### 2.2.2.1、分布式专家 Martin 对于 Relock 的质疑

在他的文章中，主要阐述了 4 个论点：

**1) 分布式锁的目的是什么？**

**第一，效率。**

使用分布式锁的互斥能力，是避免不必要地做同样的两次工作（例如一些昂贵的计算任务）。如果锁失效，并不会带来「恶性」的后果，例如发了 2 次邮件等，无伤大雅。

**第二，正确性。**

使用锁用来防止并发进程互相干扰。如果锁失效，会造成多个进程同时操作同一条数据，产生的后果是**数据严重错误、永久性不一致、数据丢失**等恶性问题，就像给患者服用了重复剂量的药物，后果很严重。

他认为，如果你是为了前者——效率，那么使用单机版 Redis 就可以了，即使偶尔发生锁失效（宕机、主从切换），都不会产生严重的后果。而使用 Redlock 太重了，没必要。

**而如果是为了正确性，Martin 认为 Redlock 根本达不到安全性的要求，也依旧存在锁失效的问题！**

**2) 锁在分布式系统中会遇到的问题**

Martin 表示，一个分布式系统，更像一个复杂的「野兽」，存在着你想不到的各种异常情况。

这些异常场景主要包括三大块，这也是分布式系统会遇到的三座大山：**NPC**。

- N：Network Delay，网络延迟
- P：Process Pause，进程暂停（GC）
- C：Clock Drift，时钟漂移

Martin 用一个进程暂停（GC）的例子，指出了 Redlock 安全性问题：

1. 客户端 1 请求锁定节点 A、B、C、D、E
2. 客户端 1 的拿到锁后，进入 GC（时间比较久）
3. 所有 Redis 节点上的锁都过期了
4. 客户端 2 获取到了 A、B、C、D、E 上的锁
5. 客户端 1 GC 结束，认为成功获取锁
6. 客户端 2 也认为获取到了锁，发生「冲突」

<img src="https://yusheng-picgo.oss-cn-beijing.aliyuncs.com/picgo/v2-cd0083e6816aa8824aeba1bfaab5d875_1440w.jpg" alt="img" style="zoom:50%;" />

Martin 认为，GC 可能发生在程序的任意时刻，而且执行时间是不可控的。

> 注：当然，即使是使用没有 GC 的编程语言，在发生网络延迟、时钟漂移时，也都有可能导致 Redlock 出现问题，这里 Martin 只是拿 GC 举例。

**3) 假设时钟正确的是不合理的**

又或者，当多个 Redis 节点「时钟」发生问题时，也会导致 Redlock **锁失效**。

1. 客户端 1 获取节点 A、B、C 上的锁，但由于网络问题，无法访问 D 和 E
2. 节点 C 上的时钟「向前跳跃」，导致锁到期
3. 客户端 2 获取节点 C、D、E 上的锁，由于网络问题，无法访问 A 和 B
4. 客户端 1 和 2 现在都相信它们持有了锁（冲突）

Martin 觉得，Redlock 必须「强依赖」多个节点的时钟是保持同步的，一旦有节点时钟发生错误，那这个算法模型就失效了。

> 即使 C 不是时钟跳跃，而是「崩溃后立即重启」，也会发生类似的问题。

Martin 继续阐述，机器的时钟发生错误，是很有可能发生的：

- 系统管理员「手动修改」了机器时钟
- 机器时钟在同步 NTP 时间时，发生了大的「跳跃」

总之，Martin 认为，Redlock 的算法是建立在「同步模型」基础上的，有大量资料研究表明，同步模型的假设，在分布式系统中是有问题的。

在混乱的分布式系统的中，你不能假设系统时钟就是对的，所以，你必须非常小心你的假设。

**4) 提出 fecing token 的方案，保证正确性**

相对应的，Martin 提出一种被叫作 fecing token 的方案，保证分布式锁的正确性。

这个模型流程如下：

1. 客户端在获取锁时，锁服务可以提供一个「递增」的 token
2. 客户端拿着这个 token 去操作共享资源
3. 共享资源可以根据 token 拒绝「后来者」的请求

<img src="https://pic3.zhimg.com/80/v2-bd9d1d9cf05964e36f8f5a75eecb3ef6_1440w.jpg" alt="img" style="zoom:50%;" />

这样一来，无论 NPC 哪种异常情况发生，都可以保证分布式锁的安全性，因为它是建立在「异步模型」上的。

而 Redlock 无法提供类似 fecing token 的方案，所以它无法保证安全性。

他还表示，**一个好的分布式锁，无论 NPC 怎么发生，可以不在规定时间内给出结果，但并不会给出一个错误的结果。也就是只会影响到锁的「性能」（或称之为活性），而不会影响它的「正确性」。**

Martin 的结论：

1. **Redlock 不伦不类**：它对于效率来讲，Redlock 比较重，没必要这么做，而对于正确性来说，Redlock 是不够安全的。
2. **时钟假设不合理**：该算法对系统时钟做出了危险的假设（假设多个节点机器时钟都是一致的），如果不满足这些假设，锁就会失效。
3. **无法保证正确性**：Redlock 不能提供类似 fencing token 的方案，所以解决不了正确性的问题。为了正确性，请使用有「共识系统」的软件，例如 Zookeeper。

好了，以上就是 Martin 反对使用 Redlock 的观点，看起来有理有据。

##### 2.2.3、Redis 作者 Antirez 的反驳

在 Redis 作者的文章中，重点有 3 个：

**1) 解释时钟问题**

首先，Redis 作者一眼就看穿了对方提出的最为核心的问题：**时钟问题**。

Redis 作者表示，Redlock 并不需要完全一致的时钟，只需要大体一致就可以了，允许有「误差」。

例如要计时 5s，但实际可能记了 4.5s，之后又记了 5.5s，有一定误差，但只要不超过「误差范围」锁失效时间即可，这种对于时钟的精度要求并不是很高，而且这也符合现实环境。

对于对方提到的「时钟修改」问题，Redis 作者反驳到：

1. **手动修改时钟**：不要这么做就好了，否则你直接修改 Raft 日志，那 Raft 也会无法工作...
2. **时钟跳跃**：通过「恰当的运维」，保证机器时钟不会大幅度跳跃（每次通过微小的调整来完成），实际上这是可以做到的

> 为什么 Redis 作者优先解释时钟问题？因为在后面的反驳过程中，需要依赖这个基础做进一步解释。

**2) 解释网络延迟、GC 问题**

之后，Redis 作者对于对方提出的，网络延迟、进程 GC 可能导致 Redlock 失效的问题，也做了反驳：

我们重新回顾一下，Martin 提出的问题假设：

1. 客户端 1 请求锁定节点 A、B、C、D、E
2. 客户端 1 的拿到锁后，进入 GC
3. 所有 Redis 节点上的锁都过期了
4. 客户端 2 获取节点 A、B、C、D、E 上的锁
5. 客户端 1 GC 结束，认为成功获取锁
6. 客户端 2 也认为获取到锁，发生「冲突」

<img src="https://pic2.zhimg.com/80/v2-cd0083e6816aa8824aeba1bfaab5d875_1440w.jpg" alt="img" style="zoom:50%;" />

Redis 作者反驳到，这个假设其实是有问题的，Redlock 是可以保证锁安全的。

这是怎么回事呢？

还记得前面介绍 Redlock 流程的那 5 步吗？这里我再拿过来让你复习一下。

1. 客户端先获取「当前时间戳T1」
2. 客户端依次向这 5 个 Redis 实例发起加锁请求（用前面讲到的 SET 命令），且每个请求会设置超时时间（毫秒级，要远小于锁的有效时间），如果某一个实例加锁失败（包括网络超时、锁被其它人持有等各种异常情况），就立即向下一个 Redis 实例申请加锁
3. 如果客户端从 3 个（大多数）以上 Redis 实例加锁成功，则再次获取「当前时间戳T2」，如果 T2 - T1 < 锁的过期时间，此时，认为客户端加锁成功，否则认为加锁失败
4. 加锁成功，去操作共享资源（例如修改 MySQL 某一行，或发起一个 API 请求）
5. 加锁失败，向「全部节点」发起释放锁请求（前面讲到的 Lua 脚本释放锁）

**注意，重点是 1-3，在步骤 3，加锁成功后为什么要重新获取「当前时间戳T2」？还用 T2 - T1 的时间，与锁的过期时间做比较？**

Redis 作者强调：如果在 1-3 发生了网络延迟、进程 GC 等耗时长的异常情况，那在第 3 步 T2 - T1，是可以检测出来的，如果超出了锁设置的过期时间，那这时就认为加锁会失败，之后释放所有节点的锁就好了！

Redis 作者继续论述，如果对方认为，发生网络延迟、进程 GC 是在步骤 3 之后，也就是客户端确认拿到了锁，去操作共享资源的途中发生了问题，导致锁失效，那这**不止是 Redlock 的问题，任何其它锁服务例如 Zookeeper，都有类似的问题，这不在讨论范畴内。**

这里我举个例子解释一下这个问题：

1. 客户端通过 Redlock 成功获取到锁（通过了大多数节点加锁成功、加锁耗时检查逻辑）
2. 客户端开始操作共享资源，此时发生网络延迟、进程 GC 等耗时很长的情况
3. 此时，锁过期自动释放
4. 客户端开始操作 MySQL（此时的锁可能会被别人拿到，锁失效）

Redis 作者这里的结论就是：

- 客户端在拿到锁之前，无论经历什么耗时长问题，Redlock 都能够在第 3 步检测出来
- 客户端在拿到锁之后，发生 NPC，那 Redlock、Zookeeper 都无能为力

所以，Redis 作者认为 Redlock 在保证时钟正确的基础上，是可以保证正确性的。

**3) 质疑 fencing token 机制**

Redis 作者对于对方提出的 fecing token 机制，也提出了质疑，主要分为 2 个问题。

**第一**，这个方案必须要求要操作的「共享资源服务器」有拒绝「旧 token」的能力。

例如，要操作 MySQL，从锁服务拿到一个递增数字的 token，然后客户端要带着这个 token 去改 MySQL 的某一行，这就需要利用 MySQL 的「事务隔离性」来做。

```text
// 两个客户端必须利用事物和隔离性达到目的
// 注意 token 的判断条件
UPDATE table T SET val = $new_val WHERE id = $id AND current_token < $token
```

但如果操作的不是 MySQL 呢？例如向磁盘上写一个文件，或发起一个 HTTP 请求，那这个方案就无能为力了，这对要操作的资源服务器，提出了更高的要求。

也就是说，大部分要操作的资源服务器，都是没有这种互斥能力的。

**再者，既然资源服务器都有了「互斥」能力，那还要分布式锁干什么？**

所以，Redis 作者认为这个方案是站不住脚的。

**第二**，退一步讲，即使 Redlock 没有提供 fecing token 的能力，但 Redlock 已经提供了随机值（就是前面讲的 UUID），利用这个随机值，也可以达到与 fecing token 同样的效果。

如何做呢？

> Redis 作者只是提到了可以完成 fecing token 类似的功能，但却没有展开相关细节，根据我查阅的资料，大概流程应该如下，如有错误，欢迎交流~

1. 客户端使用 Redlock 拿到锁
2. 客户端在操作共享资源之前，先把这个锁的 VALUE，在要操作的共享资源上做标记
3. 客户端处理业务逻辑，最后，在修改共享资源时，判断这个标记是否与之前一样，一样才修改（类似 CAS 的思路）

还是以 MySQL 为例，举个例子就是这样的：

1. 客户端使用 Redlock 拿到锁
2. 客户端要修改 MySQL 表中的某一行数据之前，先把锁的 VALUE 更新到这一行的某个字段中（这里假设为 current_token 字段)
3. 客户端处理业务逻辑
4. 客户端修改 MySQL 的这一行数据，把 VALUE 当做 WHERE 条件，再修改

```text
UPDATE table T SET val = $new_val WHERE id = $id AND current_token = $redlock_value
```

可见，这种方案依赖 MySQL 的事务机制，也达到对方提到的 fecing token 一样的效果。

但这里还有个小问题，是网友参与问题讨论时提出的：**两个客户端通过这种方案，先「标记」再「检查+修改」共享资源，那这两个客户端的操作顺序无法保证啊？**

而用 Martin 提到的 fecing token，因为这个 token 是单调递增的数字，资源服务器可以拒绝小的 token 请求，保证了操作的「顺序性」！

Redis 作者对这问题做了不同的解释，我觉得很有道理，他解释道：**分布式锁的本质，是为了「互斥」，只要能保证两个客户端在并发时，一个成功，一个失败就好了，不需要关心「顺序性」。**

> 前面 Martin 的质疑中，一直很关心这个顺序性问题，但 Redis 的作者的看法却不同。

综上，Redis 作者的结论：

1. **作者同意对方关于「时钟跳跃」对 Redlock 的影响，但认为时钟跳跃是可以避免的，取决于基础设施和运维。**
2. **Redlock 在设计时，充分考虑了 NPC 问题，在 Redlock 步骤 3 之前出现 NPC，可以保证锁的正确性，但在步骤 3 之后发生 NPC，不止是 Redlock 有问题，其它分布式锁服务同样也有问题，所以不在讨论范畴内。**

#### 2.3 redission

现在常用的redis第三方分布式锁框架，实现了很多分布式锁的方案，比如：

- 可重入锁（Reentrant Lock）
- 公平锁（Fair Lock）
- 联锁（MultiLock）
- 红锁（RedLock）
- 读写锁（ReadWriteLock）
- 信号量（Semaphore）
- 可过期性信号量（PermitExpirableSemaphore）
- 闭锁（CountDownLatch）

采用监视器狗watchDog，俗称看门狗，来解决NPC问题。即起一个守护线程，对锁进行自动续期。

### 3、zookeeper锁

#### 3.1 写锁

##### 3.1.1 临时节点实现

基于Zookeeper临时节点实现的分布式锁是这样的：

1. 客户端 1 和 2 都尝试创建「临时节点」，例如 /lock
2. 假设客户端 1 先到达，则加锁成功，客户端 2 加锁失败
3. 客户端 1 操作共享资源
4. 客户端 1 删除 /lock 节点，释放锁

##### 3.1.2 序列号实现

基于Zookeeper序列号实现的分布式锁是这样的：

1. 客户端 1 和 2 都在「永久节点」（例如 /lock）下面创建顺序临时节点，每个节点都带上序列号
2. 获取/lock下的所有临时节点，客户端 1 判断自己是序列号最小的节点，获得锁。客户端2等待
3. 客户端 1 操作共享资源
4. 客户端 1 删除 /lock下自己的临时节点，释放锁

#### 2. 读锁

与上面的序列号实现类似

1. 客户端 1 和 2 都在「永久节点」，（例如 /lock）下面创建顺序临时节点，每个节点都带上序列号，且名称用read和write区分读请求和写请求
2. 获取/lock下的所有临时节点，客户端 1 判断自己是序列号最小的节点或者比自己序列号小的都是读请求，获得锁。客户端2判断不是，则等待
3. 客户端 1 操作共享资源
4. 客户端 1 删除 /lock下自己的临时节点，释放锁

#### 3. zookeeper分布式锁是不是一定完美？

其实不然。

思考一下，客户端 1 创建临时节点后，Zookeeper 是如何保证让这个客户端一直持有锁呢？

原因就在于，**客户端 1 此时会与 Zookeeper 服务器维护一个 Session，这个 Session 会依赖客户端「定时心跳」来维持连接。**

如果 Zookeeper 长时间收不到客户端的心跳，就认为这个 Session 过期了，也会把这个临时节点删除。

<img src="https://pic2.zhimg.com/80/v2-c5c31a4f5b3975d580ba026c495d63fd_1440w.jpg" alt="img" style="zoom:50%;" />

同样地，基于此问题，我们也讨论一下 GC 问题对 Zookeeper 的锁有何影响：

1. 客户端 1 创建临时节点 /lock 成功，拿到了锁
2. 客户端 1 发生长时间 GC
3. 客户端 1 无法给 Zookeeper 发送心跳，Zookeeper 把临时节点「删除」
4. 客户端 2 创建临时节点 /lock 成功，拿到了锁
5. 客户端 1 GC 结束，它仍然认为自己持有锁（冲突）

可见，即使是使用 Zookeeper，也无法保证进程 GC、网络延迟异常场景下的安全性。

**这就是前面 Redis 作者在反驳的文章中提到的：如果客户端已经拿到了锁，但客户端与锁服务器发生「失联」（例如 GC），那不止 Redlock 有问题，其它锁服务都有类似的问题，Zookeeper 也是一样！**

所以，这里我们就能得出结论了：**一个分布式锁，在极端情况下，不一定是安全的。**

**如果你的业务数据非常敏感，在使用分布式锁时，一定要注意这个问题，不能假设分布式锁 100% 安全**。

好，现在我们来总结一下 Zookeeper 在使用分布式锁时优劣：

优点：

1. 不需要考虑锁的过期时间
2. watch 机制，加锁失败，可以 watch 等待锁释放，实现乐观锁

缺点：

1. 性能不如 Redis
2. 部署和运维成本高
3. 客户端与 Zookeeper 的长时间失联，锁被释放问题

## 参考链接

[Redis分布式锁](https://zhuanlan.zhihu.com/p/360310753#:~:text=%E4%BB%80%E4%B9%88%E6%98%AF%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81.%20%E8%AF%B4%E5%88%B0Redis%EF%BC%8C%E6%88%91%E4%BB%AC%E7%AC%AC%E4%B8%80%E6%83%B3%E5%88%B0%E7%9A%84%E5%8A%9F%E8%83%BD%E5%B0%B1%E6%98%AF%E5%8F%AF%E4%BB%A5%E7%BC%93%E5%AD%98%E6%95%B0%E6%8D%AE%EF%BC%8C%E9%99%A4%E6%AD%A4%E4%B9%8B%E5%A4%96%EF%BC%8CRedis%E5%9B%A0%E4%B8%BA%E5%8D%95%E8%BF%9B%E7%A8%8B%E3%80%81%E6%80%A7%E8%83%BD%E9%AB%98%E7%9A%84%E7%89%B9%E7%82%B9%EF%BC%8C%E5%AE%83%E8%BF%98%E7%BB%8F%E5%B8%B8%E8%A2%AB%E7%94%A8%E4%BA%8E%E5%81%9A%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E3%80%82.%20%E9%94%81%E6%88%91%E4%BB%AC%E9%83%BD%E7%9F%A5%E9%81%93%EF%BC%8C%E5%9C%A8%E7%A8%8B%E5%BA%8F%E4%B8%AD%E7%9A%84%E4%BD%9C%E7%94%A8%E5%B0%B1%E6%98%AF%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7%EF%BC%8C%E4%BF%9D%E8%AF%81%E5%85%B1%E4%BA%AB%E8%B5%84%E6%BA%90%E5%9C%A8%E5%90%8C%E4%B8%80%E6%97%B6%E5%88%BB%E5%8F%AA%E8%83%BD%E8%A2%AB%E4%B8%80%E4%B8%AA%E7%BA%BF%E7%A8%8B%E8%AE%BF%E9%97%AE%EF%BC%8CJava%E4%B8%AD%E7%9A%84%E9%94%81%E6%88%91%E4%BB%AC%E9%83%BD%E5%BE%88%E7%86%9F%E6%82%89%E4%BA%86%EF%BC%8C%E5%83%8Fsynchronized,%E3%80%81Lock%E9%83%BD%E6%98%AF%E6%88%91%E4%BB%AC%E7%BB%8F%E5%B8%B8%E4%BD%BF%E7%94%A8%E7%9A%84%EF%BC%8C%E4%BD%86%E6%98%AFJava%E7%9A%84%E9%94%81%E5%8F%AA%E8%83%BD%E4%BF%9D%E8%AF%81%E5%8D%95%E6%9C%BA%E7%9A%84%E6%97%B6%E5%80%99%E6%9C%89%E6%95%88%EF%BC%8C%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E5%B0%B1%E6%97%A0%E8%83%BD%E4%B8%BA%E5%8A%9B%E4%BA%86%EF%BC%8C%E8%BF%99%E4%B8%AA%E6%97%B6%E5%80%99%E6%88%91%E4%BB%AC%E5%B0%B1%E9%9C%80%E8%A6%81%E7%94%A8%E5%88%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E3%80%82.%20%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%EF%BC%8C%E9%A1%BE%E5%90%8D%E6%80%9D%E4%B9%89%EF%BC%8C%E5%B0%B1%E6%98%AF%E5%88%86%E5%B8%83%E5%BC%8F%E9%A1%B9%E7%9B%AE%E5%BC%80%E5%8F%91%E4%B8%AD%E7%94%A8%E5%88%B0%E7%9A%84%E9%94%81%EF%BC%8C%E5%8F%AF%E4%BB%A5%E7%94%A8%E6%9D%A5%E6%8E%A7%E5%88%B6%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E4%B9%8B%E9%97%B4%E5%90%8C%E6%AD%A5%E8%AE%BF%E9%97%AE%E5%85%B1%E4%BA%AB%E8%B5%84%E6%BA%90%EF%BC%8C%E4%B8%80%E8%88%AC%E6%9D%A5%E8%AF%B4%EF%BC%8C%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E9%9C%80%E8%A6%81%E6%BB%A1%E8%B6%B3%E7%9A%84%E7%89%B9%E6%80%A7%E6%9C%89%E8%BF%99%E4%B9%88%E5%87%A0%E7%82%B9%EF%BC%9A.%202%E3%80%81%E9%AB%98%E5%8F%AF%E7%94%A8%E6%80%A7%EF%BC%9A%E5%9C%A8%E5%88%86%E5%B8%83%E5%BC%8F%E5%9C%BA%E6%99%AF%E4%B8%8B%EF%BC%8C%E4%B8%80%E5%B0%8F%E9%83%A8%E5%88%86%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%95%E6%9C%BA%E4%B8%8D%E5%BD%B1%E5%93%8D%E6%AD%A3%E5%B8%B8%E4%BD%BF%E7%94%A8%EF%BC%8C%E8%BF%99%E7%A7%8D%E6%83%85%E5%86%B5%E5%B0%B1%E9%9C%80%E8%A6%81%E5%B0%86%E6%8F%90%E4%BE%9B%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E6%9C%8D%E5%8A%A1%E4%BB%A5%E9%9B%86%E7%BE%A4%E7%9A%84%E6%96%B9%E5%BC%8F%E9%83%A8%E7%BD%B2%EF%BC%9B.)

[Redission分布式锁](https://juejin.cn/post/6961380552519712798)

