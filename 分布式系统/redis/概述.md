<img src="https://yusheng-picgo.oss-cn-beijing.aliyuncs.com/picgo/redis-tree.png" alt="redis-tree" style="zoom:30%;" />

[TOC]

## 基础数据结构

#### 数据结构

##### SDS

```c
struct sdshdr {
    unsigned int len;   //buf中已经使用的长度
    unsigned int free;  //buf中未使用的长度
    char buf[];         //柔性数组buf
}
```

这里对于字符串的存储通过一个char数组进行存储，len表示长度，free表示剩余长度。优点：

- 空间预分配：redis数据操作次数多，那么每次对于字符串操作就分配新的内存是不现实的。所以给字符串操作后分配多一点的内存是redis系统中的一个功能。比如将二个长度字符串为5的合并在一起，如果一个sds的buf长度不够，那么就会分配10(合并长度)+10(预分配长度)的长度。

- 二进制安全:不同于C语言以\0结尾，redis提取字符串是依据长度提取这样就保证安全。

##### 链表

常规的双向链表，redis功能比如列表键、发布订阅、监视器等都使用这一结构

##### 字典

```c
typedef struct dict{
   //类型特定函数
	dictType *type;
	//私有数据
	void *privdata;
	//哈希表
	dictht ht[2];
	//rehash索引
	//当rehash不在进行时，值为-1
	int rehashidx;
}dict;
```

redis里面哈希表(dictht)底层是通过数组+链表的形式组成的。而字典里面对于哈希表进行了一次包装，里面包含有两个哈希表，使用2个哈希表是为了rehash的均摊做准备。

###### rehash

通常的rehash比如java里面是创建一个两倍的entry数组然后把数据重新hash一遍。但是一遍rehash过于耗时，redis采取渐进式的方法去rehash。假设当前数据在ht[0]中并且数据已经过了阈值那么就会分配一个两倍ht[0]的数组到ht[1]中,在字典中维持一个索引计数器rehashidx，每次对于字典的操作都会让rehashidx加一并对于ht[0]中的对应行ht[0][rehashidx]中的数据重新hash到ht[1]表中。

**注意：**程序在执行bgsave或者bgrewriteof的时候不能rehash

##### 跳跃表

常见的跳表，数据有序。拥有比二叉搜索树更简单的结构，但确有相近的查询性能。插入/新增数据比较麻烦，有可能需要重建索引。

##### 整数集合

```c
typedef struct intset {
    uint32_t encoding;  // 编码类型 int16_t、int32_t、int64_t
    uint32_t length;    // 长度 最大长度:2^32
    int8_t contents[];  // 柔性数组
} intset;
```

整数数据有序的存储在contents数组里面，通过二分查找来查找元素

##### 压缩列表

连续，无序的数据结构。压缩列表是 Redis 为了节约内存而开发的， 由一系列**特殊编码的连续内存块**组成的**顺序型（sequential）数据结构**

#### 对象

##### 字符串

String是 Redis 最简单最常用的数据结构，也是 Memcached 唯一的数据结构。在平时的开发中，我们通常用它缓存字符串类型的业务数据以及用作计数器（incr命令）。
###### 底层实现

- 如果一个字符串对象保存的是整数值， 并且这个整数值可以用 long 类型来表示， 那么字符串对象会将整数值保存在字符串对象结构的 ptr 属性里面（将 void* 转换成 long ）， 并将字符串对象的编码设置为 int 。
- 如果字符串对象保存的是一个字符串值， 并且这个字符串值的长度大于 39 字节， 那么字符串对象将使用一个简单动态字符串（SDS）来保存这个字符串值， 并将对象的编码设置为 raw。
- 如果字符串对象保存的是一个字符串值， 并且这个字符串值的长度小于等于 39 字节， 那么字符串对象将使用 embstr 编码的方式来保存这个字符串值。

##### 列表

list 是有序可重复列表，和 Java 的 List 蛮像的，查询速度快，可以通过索引查询；插入删除速度慢。

###### 底层实现

- 列表对象的编码可以是 ziplist 或者 linkedlist 。
- 列表对象保存的所有字符串元素的长度都小于 64 字节并且保存的元素数量小于 512 个，使用 ziplist 编码；否则使用 linkedlist；

###### 使用场景

- 消息队列：Redis 的 list 是有序的列表结构，可以实现阻塞队列，使用左进右出的方式。Lpush 用来生产 从左侧插入数据，Brpop 用来消费，用来从右侧 **阻塞**的消费数据。
- 数据的分页展示： lrange 命令需要两个索引来获取数据，这个就可以用来实现分页，可以在代码中计算两个索引值，然后来 redis 中取数据。
- 可以用来实现粉丝列表以及最新消息排行等功能。

##### 哈希

Redis 散列可以存储多个键值对之间的映射。和字符串一样，散列存储的值既可以是字符串又可以是数值，并且用户同样可以对散列存储的数字值执行自增或自减操作。这个和 Java 的 HashMap 很像，每个 HashMap 有自己的名字，同时可以存储多个 k/v 对。
###### 底层实现

- 哈希对象的编码可以是 ziplist 或者 hashtable 。
- 哈希对象保存的所有键值对的键和值的字符串长度都小于 64 字节并且保存的键值对数量小于 512 个，使用ziplist 编码；否则使用hashtable；

###### 应用场景

- Hash 更适合存储结构化的数据，比如 Java 中的对象；其实 Java 中的对象也可以用 string 进行存储，只需要将 对象 序列化成 json 串就可以，但是如果这个对象的某个属性更新比较频繁的话，那么每次就需要重新将整个对象序列化存储，这样消耗开销比较大。可如果用 hash 来存储 对象的每个属性，那么每次只需要更新要更新的属性就可以。
- 购物车场景：可以以用户的id为key，商品的id 为存储的field，商品数量为键值对的value，这样就构成了购物车的三个要素。

##### 集合

Redis 的set和list都可以存储多个字符串，他们之间的不同之处在于，list是有序可重复，而set是无序不可重复。
###### 底层实现

- 集合对象的编码可以是 intset 或者 hashtable 。
- 集合对象保存的所有元素都是整数值并且保存的元素数量不超过 512 个，使用intset 编码；否则使用hashtable；

###### 应用场景

- 标签：可以将博客网站每个人的标签用 set 集合存储，然后还按每个标签 将用户进行归并。
- 存储好友/粉丝：set 具有去重功能；还可以利用set并集功能得到共同好友之类的功能。

##### 有序集合

有序集合和散列一样，都用于存储键值对：其中有序集合的每个键称为成员（member），都是独一无二的，而有序集合的每个值称为分值（score），都必须是浮点数。可以根据分数进行排序，有序集合是Redis里面唯一既可以根据成员访问元素（这一点和散列一样），又可以根据分值以及分值的排列顺序来访问元素的结构。和Redis的其他结构一样，用户可以对有序集合执行添加、移除和获取等操作。
###### 底层实现

- 有序集合的编码可以是 ziplist 或者 skiplist
- 有序集合保存的元素数量小于 128 个并且保存的所有元素成员的长度都小于 64 字节。使用 ziplist 编码；否则使用skiplist；

###### 应用场景

- 排行榜：有序集合最常用的场景。如新闻网站对热点新闻排序，比如根据点击量、点赞量等。
- 带权重的消息队列：重要的消息 score 大一些，普通消息 score 小一些，可以实现优先级高的任务先执行。

#### 高级对象

除去上面五种基本对象，redis还有三种高级对象

##### HyperLogLog

Redis 在 2.8.9 版本添加了 HyperLogLog 结构。Redis HyperLogLog 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定 的、并且是很小的。在 Redis 里面，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基 数。这和计算基数时，元素越多耗费内存就越多的集合形成鲜明对比。但是，因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。

###### 应用场景

- 可以用来统计网站的登陆人数以及其他指标

##### GEO

在 Redis 3.2 版本中新增了一种叫 geo 的数据结构，它主要用来存储地理位置信息，并对存储的信息进行操作。

###### 应用场景

- 用于存储地理信息以及对地理信息作操作的场景。

##### BloomFilter

一种数据结构，是由一串很长的二进制向量组成，可以将其看成一个二进制数组。既然是二进制，那么里面存放的不是0，就是1，但是初始默认值都是0。他的主要作用是：**判断一个元素是否在某个集合中**。add操作会将多个hash函数计算处下标元素至为1。contains操作会判断元素是否在集合中。如果有一个0，则元素一定不存在；如果全为1，则元素可能存在也可能不存在。因为这些1有可能是其他元素映射的。布隆过滤器里元素越多，则误差越大。

1. 优点：优点很明显，二进制组成的数组，占用内存极少，并且插入和查询速度都足够快。
2. 缺点：随着数据的增加，误判率会增加；还有无法判断数据一定存在；另外还有一个重要缺点，无法删除数据。

可使用redis官方插件RedisBloom。

###### 应用场景

- 解决缓存穿透问题：一般得查询场景都是先去查询缓存，如果缓存没有，那么就去 DB 查询，如果查到了，先存在 缓存 中，然后返回给调用方。如果查不到就返回空。这种情况如果有人频繁的请求缓存中没有得数据，比如id = -1 得数据，那么会对 DB 造成极大得压力，这种情况就可以使用 redis 得布隆过滤器了，可以先将可能得id都存在布隆过滤器中，当查询来的时候，先去布隆过滤器查，如果查不到直接返回，不请求缓存以及DB，如果存在 布隆过滤器 中，那么才去缓存中取数据。
- 黑名单校验：可以将黑名单中得ip放入到布隆过滤器中，这样不用每次来都去 db 中查询了。

#### 过期策略

redis中有两个重要的字典。一个用来存储实际的业务数据，该字典的value就是上面的各种对象；还有一个是过期字典，用来存储上面业务key的过期时间。redis的过期策略是通过定期删除和惰性删除配合实现的。

##### 定期删除

Redis 默认会每秒进行十次过期扫描（100ms一次），过期扫描不会遍历过期字典中所有的 key，而是采用了一种简单的贪心策略。

1. 从过期字典中随机 20 个 key；

2. 删除这 20 个 key 中已经过期的 key；

3. 如果过期的 key 比率超过 1/4，那就重复步骤 1；

##### 惰性删除

redis在访问某个key时，如果这个key设置了过期时间，那么那就会现在过期字典里检查这个key是否过期，如果已过期，则删除这个key，返回空。

#### 内存淘汰策略

redis总共有三类、八种内存淘汰算法。

###### 直接拒绝

- noeviction：当内存使用超过配置的时候会返回错误，不会驱逐任何键

###### 过期建淘汰策略

- volatile-lru：加入键的时候如果过限，首先从设置了过期时间的键集合中驱逐最久没有使用的键
- volatile-lfu：从所有配置了过期时间的键中驱逐使用频率最少的键
- volatile-random：加入键的时候如果过限，从过期键的集合中随机驱逐
- volatile-ttl：从配置了过期时间的键中驱逐马上就要过期的键

###### 所有键淘汰策略

- allkeys-lru：加入键的时候，如果过限，首先通过LRU算法驱逐最久没有使用的键
- allkeys-lfu：从所有键中驱逐使用频率最少的键
- allkeys-random：加入键的时候如果过限，从所有key随机删除

## 高级功能

#### 事务

Redis 通过 [MULTI](http://redis.readthedocs.org/en/latest/transaction/multi.html#multi) 、 [DISCARD](http://redis.readthedocs.org/en/latest/transaction/discard.html#discard) 、 [EXEC](http://redis.readthedocs.org/en/latest/transaction/exec.html#exec) 和 [WATCH](http://redis.readthedocs.org/en/latest/transaction/watch.html#watch) 四个命令来实现事务功能。Redis 事务可以一次执行多个命令， 并且带有以下三个重要的保证：

- 批量操作在发送 EXEC 命令前被放入队列缓存。
- 收到 EXEC 命令后进入事务执行，事务中任意命令执行失败，其余的命令依然被执行。
- 在事务执行过程，其他客户端提交的命令请求不会插入到事务执行命令序列中。

一个事务从开始到执行会经历以下三个阶段：

- 开始事务。
- 命令入队。
- 执行事务。

正常MULTI和EXEC即可执行一个事务，但是我们也可以通过WATCH命令来增强事务的能力。

###### WATCH命令的实现

在每个代表数据库的 `redis.h/redisDb` 结构类型中， 都保存了一个 `watched_keys` 字典， 字典的键是这个数据库被监视的键， 而字典的值则是一个链表， 链表中保存了所有监视这个键的客户端。比如说，以下字典就展示了一个 `watched_keys` 字典的例子：

![image-20220922104752208](https://yusheng-picgo.oss-cn-beijing.aliyuncs.com/picgo/image-20220922104752208.png)

此时如果被监听的键被修改，监听这个键的客户端中的REDIS_DIRTY_CAS标识会被打开，当EXEC命令执行时，会检查该标识，如果被打开，则说明至少有一个客户端修改了找个键，则事务失败，否则执行成功。

**redis事务功能不够健全，比较鸡肋，不建议使用。一般如果需要事务能力，可以使用Lua脚本代替**

#### 管道

redis管道可以简单理解为命令的批处理，主要为了降低`RTT(Round Trip Time)` 对性能的影响，比如有1000个redis命令，正常我们需要1000次的网络IO，但是如果使用管道，我们可以将这1000个命令缓存在本地，然后一次性的发送给服务端，服务端在等待所有命令处理完后，才会一次性的返回命令结果，这样就将1000次网络IO降低成了一次。

与事务不同的是，管道不保证命令执行的原子性，即这批命令可以被其他客户端插队。

#### Lua脚本

`redis` 从 2.6 版本开始引入对 Lua 脚本的支持，通过在服务器中嵌入 Lua 环境， `redis` 客户端可以直接使用 Lua 脚本，在服务端原子地执行多个 `redis` 命令。同时， `redis` 服务端还支持对 Lua 脚本进行缓存（使用 `SCRIPT LOAD` 或 `EVAL` 执行过的脚本服务端都会对其进行缓存），下次可以使用 `EVALSHA` 命令调用缓存的脚本，节省带宽。

一般我们可以使用Lua脚本来替代redis的事务功能，它同样提供多条命令的原子性，同时它还可以在脚本中获取中间命令的执行结果，即可以处理命令之间依赖的问题。如：

```lua
local key = KEYS[1]
local new = ARGV[1]

local current = redis.call('GET', key)
if (current == false) or (tonumber(new) < tonumber(current)) then
  redis.call('SET', key, new)
  return 1
else
  return 0
end
```

###### 管道、事务、Lua脚本的区别

- 管道：只是简单的命令批处理，不保证原子性。
- 事务：保证了多条命令执行的原子性。但是请求命令一般是单条发送的，只是结果响应是一次性返回。但是某些客户端通过管道优化了事务，使得它的请求命令也会在本地暂存，然后一次性发送给服务器。
- Lua脚本：保证了多条命令的原子性，同时还支持命令之间有依赖的情况，即后一个命令可以对前一个命令的结果做相应处理。

由于事务和Lua脚本都是保证原子性的，所以不要做一些耗时的运算，Lua脚本还要避免死循环。否则redis会阻塞，将不接受其他的命令， 所以使用时要注意。管道不会阻塞redis。

## redis6.0新特性

#### 多线程模型

Redis6.0弃用了之前的单线程reactor模型，借鉴了当前更流行的多线程主从reactor模型，来降低IO读写操作的性能开销（由于redis都是内存操作，业务逻辑处理这块不是性能瓶颈）。与通常的主从reactor模式中业务逻辑是有多线程处理不同，redis中的命令处理依然是单线程，所以你可以给它起名叫多reactor单线程模型。

![image-20220922104819203](https://yusheng-picgo.oss-cn-beijing.aliyuncs.com/picgo/image-20220922104819203.png)

1. Redis 服务器启动，开启主线程事件循环（Event Loop），注册 `acceptTcpHandler` 连接应答处理器到用户配置的监听端口对应的文件描述符，等待新连接到来；
2. 客户端和服务端建立网络连接；
3. `acceptTcpHandler` 被调用，主线程使用 AE 的 API 将 `readQueryFromClient` 命令读取处理器绑定到新连接对应的文件描述符上，并初始化一个 `client` 绑定这个客户端连接；
4. 客户端发送请求命令，触发读就绪事件，服务端主线程不会通过 socket 去读取客户端的请求命令，而是先将 `client` 放入一个 LIFO 队列 `clients_pending_read`；
5. 在事件循环（Event Loop）中，主线程执行 `beforeSleep` -->`handleClientsWithPendingReadsUsingThreads`，利用 Round-Robin 轮询负载均衡策略，把 `clients_pending_read`队列中的连接均匀地分配给 I/O 线程各自的本地 FIFO 任务队列 `io_threads_list[id]` 和主线程自己，I/O 线程通过 socket 读取客户端的请求命令，存入 `client->querybuf` 并解析第一个命令，**但不执行命令**，主线程忙轮询，等待所有 I/O 线程完成读取任务；
6. 主线程和所有 I/O 线程都完成了读取任务，主线程结束忙轮询，遍历 `clients_pending_read` 队列，**执行所有客户端连接的请求命令**，先调用 `processCommandAndResetClient` 执行第一条已经解析好的命令，然后调用 `processInputBuffer` 解析并执行客户端连接的所有命令，在其中使用 `processInlineBuffer` 或者 `processMultibulkBuffer` 根据 Redis 协议解析命令，最后调用 `processCommand` 执行命令；
7. 根据请求命令的类型（SET, GET, DEL, EXEC 等），分配相应的命令执行器去执行，最后调用 `addReply` 函数族的一系列函数将响应数据写入到对应 `client` 的写出缓冲区：`client->buf` 或者 `client->reply` ，`client->buf` 是首选的写出缓冲区，固定大小 16KB，一般来说可以缓冲足够多的响应数据，但是如果客户端在时间窗口内需要响应的数据非常大，那么则会自动切换到 `client->reply` 链表上去，使用链表理论上能够保存无限大的数据（受限于机器的物理内存），最后把 `client` 添加进一个 LIFO 队列 `clients_pending_write`；
8. 在事件循环（Event Loop）中，主线程执行 `beforeSleep` --> `handleClientsWithPendingWritesUsingThreads`，利用 Round-Robin 轮询负载均衡策略，把 `clients_pending_write` 队列中的连接均匀地分配给 I/O 线程各自的本地 FIFO 任务队列 `io_threads_list[id]` 和主线程自己，I/O 线程通过调用 `writeToClient` 把 `client` 的写出缓冲区里的数据回写到客户端，主线程忙轮询，等待所有 I/O 线程完成写出任务；
9. 主线程和所有 I/O 线程都完成了写出任务， 主线程结束忙轮询，遍历 `clients_pending_write` 队列，如果 `client` 的写出缓冲区还有数据遗留，则注册 `sendReplyToClient` 到该连接的写就绪事件，等待客户端可写时在事件循环中再继续回写残余的响应数据。

这里大部分逻辑和之前的单线程模型是一致的，变动的地方仅仅是把读取客户端请求命令和回写响应数据的逻辑异步化了，交给 I/O 线程去完成，这里需要特别注意的一点是：**I/O 线程仅仅是读取和解析客户端命令而不会真正去执行命令，客户端命令的执行最终还是要在主线程上完成**。

#### 客户端缓存

redis 6 提供了服务端追踪key的变化，客户端缓存数据的特性，但是这需要客户端实现，目前只有lettuce对其进行了支持。

![image-20220922104845608](https://yusheng-picgo.oss-cn-beijing.aliyuncs.com/picgo/image-20220922104845608.png)

执行流程：

1. 当客户端访问某个key时，服务端将记录key和client ，客户端拿到数据后，进行客户端缓存。
2. 当key再次被访问时，key将被直接返回，避免了与redis 服务器的再次交互，节省服务端资源。
3. 当数据被其他请求修改时，服务端将主动通知客户端失效的key，客户端进行本地失效，下次请求时，重新获取最新数据。

#### ACL

Redis6.0加强了对命令的访问和执行权限的控制。

## 单机架构

#### 线程模型

Redis6.0之前采用的是reactor单线程模型，底层通过epoll实现，模型如下：

![image-20220922104904210](https://yusheng-picgo.oss-cn-beijing.aliyuncs.com/picgo/image-20220922104904210.png)

从上面可以看出整个流程就是IO多路复用程序将socket放入一个事件队列中，然后事件分派器将各种socket事件（连接、读、写）放入对应的事件处理器中。

连接流程：

![image-20220922104924757](https://yusheng-picgo.oss-cn-beijing.aliyuncs.com/picgo/image-20220922104924757.png)

命令执行流程：

![image-20220922104945317](https://yusheng-picgo.oss-cn-beijing.aliyuncs.com/picgo/image-20220922104945317.png)

#### 持久化

##### RDB

在默认情况下， Redis 将内存数据库快照保存在名字为 dump.rdb 的二进制文件中。你可以对 Redis 进行设置， 让它在“ N 秒内数据集至少有 M 个改动”这一条件被满足时， 自动保存一次数据集。还可以手动执行命令生成RDB快照，进入redis客户端执行命令save或bgsave可以生成dump.rdb文件，每次命令执行都会将所有redis内存快照到一个新的rdb文件里，并覆盖原有rdb快照文件。通常为了不阻塞主进程我们会选择bgsave，bgsave是通过fork机制实现的。

save与bgsave对比：

<img src="https://yusheng-picgo.oss-cn-beijing.aliyuncs.com/picgo/image-20220921224031910.png" alt="image-20220921224031910" style="zoom:50%;" />

##### AOF(append-only file)

快照功能并不是非常耐久(durable)，如果 Redis 因为某些原因而造成故障停机， 那么服务器将丢失最近写入、且仍未保存到快照中的那些数据。从 1.1 版本开始， Redis 增加了一种完全耐久的持久化方 式：AOF 持久化，将修改的每一条指令记录进文件appendonly.aof中，先写入os cache，每隔一段时间 fsync到磁盘。你可以配置刷盘的时机，如下：

- appendfsync always：每次有新命令追加到 AOF 文件时就执行一次 fsync ，非常慢，也非常安全。
-  appendfsync everysec：每秒 fsync 一次，足够快，并且在故障时只会丢失 1 秒钟的数据。
- appendfsync no：不主动调用 fsync ，fsync时机交给操作系统来决定。更快，也更不安全的选择。

###### AOF重写

由于AOF是追加的，所以里面的命令会越来越多，并且 会有大量无用的命令--多个命令操作同一份数据。所以AOF会定期根据当前内存的最新数据来重写AOF。AOF重写同样是fork子进程。

###### RDB和AOF对比

<img src="https://yusheng-picgo.oss-cn-beijing.aliyuncs.com/picgo/image-20220921225306404.png" alt="image-20220921225306404" style="zoom:50%;" />

生产环境可以都启用，但是redis会优先选用AOF来恢复数据。

#### redis4.0 混合持久化

重启 Redis 时，我们很少使用 RDB来恢复内存状态，因为会丢失大量数据。我们通常使用 AOF 日志重放，但是重放 AOF 日志性能相对 RDB来说要慢很多，这样在 Redis 实例很大的情况下，启动需要花费很长的时间。 Redis 4.0 为了解决这个问题，带来了一个新的持久化选项——混合持久化。通过如下配置开启：

```lua
aof‐use‐rdb‐preamble yes
```

如果开启了混合持久化，AOF在重写时，不再是单纯将内存数据转换为RESP命令写入AOF文件，而是将重写这一刻之前的内存做RDB快照处理，并且将RDB快照内容和增量的AOF修改内存数据的命令存在一 起，都写入新的AOF文件，新的文件一开始不是appendonly.aof，等到重写完新的AOF文件才会进行改名，覆盖原有的AOF文件，完成新旧两个AOF文件的替换。于是在 Redis 重启的时候，可以先加载 RDB 的内容，然后再重放增量 AOF 日志就可以完全替代之前的 AOF 全量文件重放，因此重启效率大幅得到提升。文件格式如下：

<img src="https://yusheng-picgo.oss-cn-beijing.aliyuncs.com/picgo/image-20220921225812224.png" alt="image-20220921225812224" style="zoom:50%;" />

#### 主从复制

<img src="https://yusheng-picgo.oss-cn-beijing.aliyuncs.com/picgo/image-20220921232833083.png" alt="image-20220921232833083" style="zoom:50%;" />

redis的主从复制可分为全量同步、部分同步和命令传播，其中命令传播是在二者已经建立连接后，保持数据一致性的机制。全量同步是在首次建立连接时，或者断开时间较长，导致命令偏移超过了缓冲队列的最大长度时所使用的机制；部分同步是在断点重连时，数据偏离量未超过缓冲队列长度时使用的机制。二者流程如下：

###### 全量同步

![image-20220922115837943](https://yusheng-picgo.oss-cn-beijing.aliyuncs.com/picgo/image-20220922115837943.png)

1. 发送一个PSYNC命令给master请求复制数据。这个slave可以首次连接也可能是断点重连
2. master收到PSYNC命令后，会在后台进行数据持久化，通过bgsave生成最新的rdb快照文件
3. 持久化期间，master会继续接收客户端的请求，它会把这些可能修改数据集的请求命令放在一个缓冲队列中
4. 当持久化进行完毕以后，master会把这份rdb文件数据集发送给slave，slave会把接收到的数据进行持久化生成rdb，然后再加载到内存中。
5. 最后，master再将之前缓冲队列中的命令发送给slave。
6. 至此主从关系已经建立，二者数据也保持一致，后续将通过**命令传播**来持续维持数据的一致性。

如果master收到了多 个slave并发连接请求，它只会进行一次持久化，而不是一个连接一次，然后再把这一份持久化的数据发送给多个并发连接的slave。

###### 部分同步

当master和slave断开重连后，一般都会对整份数据进行复制。但从redis2.8版本开始，redis改用可以支 持部分数据复制的命令PSYNC去master同步数据，slave与master能够在网络连接断开重连后只进行部分 数据复制(断点续传)。 master会在其内存中创建一个复制数据用的缓存队列，缓存最近一段时间的数据，master和它所有的 slave都维护了复制的数据下标offset和master的进程id，因此，当网络连接断开后，slave会请求master 继续进行未完成的复制，从所记录的数据下标开始。如果master进程id变化了，或者从节点数据下标 offset太旧，已经不在master的缓存队列里了，那么将会进行一次全量数据的复制。

![image-20220922120115106](https://yusheng-picgo.oss-cn-beijing.aliyuncs.com/picgo/image-20220922120115106.png)

###### 主从复制风暴

如果过多的从节点同时从主节点复制，会导致主节点压力过大，此时可以让部分从节点从其他从节点开始复制，整体架构如下所示：

<img src="https://yusheng-picgo.oss-cn-beijing.aliyuncs.com/picgo/image-20220922151215085.png" alt="image-20220922151215085" style="zoom:50%;" />

## 多机架构

#### 哨兵架构

![image-20220922154009499](https://yusheng-picgo.oss-cn-beijing.aliyuncs.com/picgo/image-20220922154009499.png)

在redis3.0以前的版本要实现集群一般是借助哨兵sentinel工具来监控master节点的状态，如果master节点异常，则会做主从切换，将某一台slave作为master，哨兵的配置略微复杂，并且性能和高可用性等各方面表现 一般，特别是在主从切换的瞬间存在访问瞬断的情况，而且哨兵模式只有一个主节点对外提供服务，没法支持很高的并发，且单个主节点内存也不宜设置得过大，否则会导致持久化文件过大，影响数据恢复或主从同步的 效率

###### 哨兵选举过程（raft协议）：

当一个master服务器被某sentinel视为下线状态（分为主观下线和客观下线）后，该sentinel会与其他sentinel协商选出sentinel的leader进 行故障转移工作。每个发现master服务器进入下线的sentinel都可以要求其他sentinel选自己为sentinel的 leader，选举是先到先得。同时每个sentinel每次选举都会自增配置纪元(选举周期)，每个纪元中只会选择一 个sentinel的leader。如果所有超过一半的sentinel选举某sentinel作为leader。之后该sentinel进行故障转移操作，从存活的slave中选举出新的master，这个选举过程跟集群的master选举很类似（都是使用的raft协议）。 哨兵集群只有一个哨兵节点，redis的主从也能正常运行以及选举master，如果master挂了，那唯一的那个哨 兵节点就是哨兵leader了，可以正常选举新master。 不过为了高可用一般都推荐至少部署三个哨兵节点。为什么推荐奇数个哨兵节点原理跟集群奇数个master节点 类似。

#### 集群架构

![image-20220922192035125](https://yusheng-picgo.oss-cn-beijing.aliyuncs.com/picgo/image-20220922192035125.png)

Redis Cluster 将所有数据划分为 16384 个 slots(槽位)，每个节点负责其中一部分槽位。槽位的信息存储于每 个节点中。
 当 Redis Cluster 的客户端来连接集群时，它也会得到一份集群的槽位配置信息并将其缓存在客户端本地。这 样当客户端要查找某个 key 时，可以直接定位到目标节点。同时因为槽位的信息可能会存在客户端与服务器不一致的情况，还需要纠正机制来实现槽位信息的校验调整。

###### 槽位定位算法

 Cluster 默认会对 key 值使用 crc16 算法进行 hash 得到一个整数值，然后用这个整数值对 16384 进行取模 来得到具体槽位。
 HASH_SLOT = CRC16(key) mod 16384

###### 跳转重定位

 当客户端向一个错误的节点发出了指令，该节点会发现指令的 key 所在的槽位并不归自己管理，这时它会向客户端发送一个特殊的跳转指令携带目标操作的节点地址，告诉客户端去连这个节点去获取数据。客户端收到指令后除了跳转到正确的节点上去操作，还会同步更新纠正本地的槽位映射表缓存，后续所有 key 将使用新的槽位映射表。

###### Redis集群节点间的通信机制

redis cluster节点间采取gossip协议进行通信，维护集群的元数据(集群节点信息，主从角色，节点数量，各节点共享的数据等)有两种方式:集中式和gossip 

###### 集中式

优点在于元数据的更新和读取，时效性非常好，一旦元数据出现变更立即就会更新到集中式的存储中，其他节点读取的时候立即就可以立即感知到;不足在于所有的元数据的更新压力全部集中在一个地方，可能导致元数据的存储压力。 很多中间件都会借助zookeeper集中式存储元数据。

###### gossip

<img src="https://yusheng-picgo.oss-cn-beijing.aliyuncs.com/picgo/image-20220922193556011.png" alt="image-20220922193556011" style="zoom:50%;" />

gossip协议包含多种消息，包括ping，pong，meet，fail等等。

- meet: 某个节点发送meet给新加入的节点，让新节点加入集群中，然后新节点就会开始与其他节点进行通信; 
- ping:每个节点都会频繁给其他节点发送ping，其中包含自己的状态还有自己维护的集群元数据，互相通过 ping交换元数据(类似自己感知到的集群节点增加和移除，hash slot信息等);

- pong: 对ping和meet消息的返回，包含自己的状态和其他信息，也可以用于信息广播和更新;
- fail: 某个节点判断另一个节点fail之后，就发送fail给其他节点，通知其他节点，指定的节点宕机了。

gossip协议的优点在于元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续，打到所有节点上 去更新，有一定的延时，降低了压力;缺点在于元数据更新有延时可能导致集群的一些操作会有一些滞后。

###### 网络抖动

真实世界的机房网络往往并不是风平浪静的，它们经常会发生各种各样的小问题。比如网络抖动就是非常常见的一种现象，突然之间部分连接变得不可访问，然后很快又恢复正常。为解决这种问题，Redis Cluster 提供了一种选项cluster­-node­-timeout，表示当某个节点持续 timeout 的时间失联时，才可以认定该节点出现故障（主观下线，后续还需要哨兵或者集群中master节点投票），需要进行主从切换。如果没有这个选项，网络抖动会导致主从频繁切换 (数据的重新复制)。

###### 集群选举（raft）

当slave发现自己的master变为FAIL状态时，便尝试进行Failover，以期成为新的master。由于挂掉的master 可能会有多个slave，从而存在多个slave竞争成为master节点的过程， 其过程如下: 

1. slave发现自己的master变为FAIL 
2. 将自己记录的集群currentEpoch加1，并广播FAILOVER_AUTH_REQUEST 信息
3. 其他节点收到该信息，只有master响应，判断请求者的合法性，并发送FAILOVER_AUTH_ACK，对每一个 epoch只发送一次ack
4. 尝试failover的slave收集master返回的FAILOVER_AUTH_ACK 
5. slave收到超过半数master的ack后变成新Master(这里解释了集群为什么至少需要三个主节点，如果只有两 个，当其中一个挂了，只剩一个主节点是不能选举成功的)
6. slave广播Pong消息通知其他集群节点。

从节点并不是在主节点一进入 FAIL 状态就马上尝试发起选举，而是有一定延迟，一定的延迟确保我们等待 FAIL状态在集群中传播，slave如果立即尝试选举，其它masters或许尚未意识到FAIL状态，可能会拒绝投票 •延迟计算公式:

DELAY = 500ms + random(0 ~ 500ms) + SLAVE_RANK * 1000ms

•SLAVE_RANK表示此slave已经从master复制数据的总量的rank。Rank越小代表已复制的数据越新。这种方式下，持有最新数据的slave将会首先发起选举(理论上)。

## 参考文档

https://segmentfault.com/a/1190000039223696
